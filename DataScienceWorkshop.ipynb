{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "tJ3Hcz1R9tIT",
    "outputId": "c16bf519-bad3-4d2b-c8e5-43a7819a76dc"
   },
   "outputs": [],
   "source": [
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "e0glevjV_jfU"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "DNHss1Aq96QU"
   },
   "outputs": [],
   "source": [
    "column_names = [\n",
    "    \"Age\", \"WorkClass\", \"fnlwgt\", \"Education\", \"EducationNum\",\n",
    "    \"MaritalStatus\", \"Occupation\", \"Relationship\", \"Race\", \"Gender\",\n",
    "    \"CapitalGain\", \"CapitalLoss\", \"HoursPerWeek\", \"NativeCountry\", \"Income\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kq4hC_0OXTvU"
   },
   "source": [
    "I am using [Pandas](https://pandas.pydata.org/) to read an manipulate the data. It makes it easy to work with tabular data and is the default data tool for most data-science work.\n",
    "\n",
    "The dataformat is a [DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "BXLCqnWo_X46"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('adult.data', names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "id": "X7DMI-Vb_inw",
    "outputId": "c5fc96f1-3439-4b72-c3d0-9d15a04f98e8"
   },
   "outputs": [],
   "source": [
    "# quick look at the top few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xYhFBrH2_n5w",
    "outputId": "5d0945fc-b911-427c-f366-fa5c9438dce7"
   },
   "outputs": [],
   "source": [
    "# and get a sense of the size of the dataframe\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Luvc3wnXiX-"
   },
   "source": [
    "Pandas can access columns by their string names. In this case we want to turn the `Income` column into a target variable (the thing we are trying to predict). Everything matching ` >50K` is turned into a `True` and everything else is a `False`. This 'binary target' is the bread-and-butter of classification.\n",
    "\n",
    "As a technical note, when you use a string to grab a column from a pandas dataframe, it returns a [Series](https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.Series.html). I use the `.values` attribute to get a numpy array and then turn the `True` and `False` values into `1` and `0` values by [casting](https://www.w3schools.com/python/python_casting.asp) the values to `int`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "CO9RcSqi_rbA"
   },
   "outputs": [],
   "source": [
    "y = (df['Income'] == ' >50K').values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "tDkZt0pzAmdB"
   },
   "outputs": [],
   "source": [
    "use_columns = ['Age', 'HoursPerWeek']\n",
    "X = df[use_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hHdcfe8XU4dT"
   },
   "source": [
    "We are almost ready to fit our first model, but before we do, we need to create training and testing sets. Why is it necessary to split our data? We want to be sure we are not [overfitting](https://elitedatascience.com/overfitting-in-machine-learning) ([wiki](https://en.wikipedia.org/wiki/Overfitting)).\n",
    "\n",
    "If we had a model that fit the training perfectly, it may not generalize well to new data.\n",
    "\n",
    "We are going to be using many functions from the standard package [scikit-learn](https://scikit-learn.org/stable/tutorial/basic/tutorial.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "4HttoqzaBicb"
   },
   "outputs": [],
   "source": [
    "# splits both X and y into train and testing data - I am using the `random_state` argument to reproduce the same results\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=432345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o_jyGAq8UMHq"
   },
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Let's start with one of the simplest models: [logistic regression](https://en.wikipedia.org/wiki/Logistic_regression). By default, this model adds \"[regularization](https://developers.google.com/machine-learning/crash-course/regularization-for-simplicity/l2-regularization)\". In this case an \"L2\" regularization. In practical terms this makes a model that 1) tries to fit the data as well as possible while 2) keep the coefficients as small as possible. This second part helps to avoid overfitting by not letting the model fit too closely to our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "MeGHUirqBi9g"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "RZrAj0ApIp_V"
   },
   "outputs": [],
   "source": [
    "# initialize the model by calling the class `LogisticRegression`\n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "Dq6CTzYqIqvk",
    "outputId": "e39d67ce-60c2-42f6-c430-c109764168cb"
   },
   "outputs": [],
   "source": [
    "# now that we have our model we can call the `fit` method\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yxDtU321JAUW",
    "outputId": "15e83405-1138-40b9-a2fe-aa32f6cb61e4"
   },
   "outputs": [],
   "source": [
    "# get the predicted classes (0 or 1)\n",
    "model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "dYs1sYAkJpvT",
    "outputId": "35a037b9-093c-4ef9-8dc2-f08bb35fc5b5"
   },
   "outputs": [],
   "source": [
    "# get the odds (probability) of each class this is an Nx2 array where the first column contains the probability of the first class\n",
    "model.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y9C6yKoBRBI7"
   },
   "source": [
    "### Testing our model\n",
    "\n",
    "We want to see how good our model is at fitting the data. This is a classification model, so one sensible way of seeing how good our model would be would be to look at the \"accuracy\", that is, how often does something that we say should happen actually happen and how often does something we say shouldn't happen not happen (see: https://en.wikipedia.org/wiki/Evaluation_of_binary_classifiers for more). \n",
    "\n",
    "Accuracy can be a misleading metric based on the base rate of the event. If the event usually happens 99% of the time, a classifier could get 99% accuracy by just guessing that event all the time. \n",
    "\n",
    "A better metric would balance both the true positive rate (how often the thing we predicted happened) and the false positive rate (how often the thing we predicted didn't happen). A popular metric for that is the \"area under the receiving operator curve\" or [AUROC](http://fastml.com/what-you-wanted-to-know-about-auc/) (sometimes just called AUC).\n",
    "\n",
    "This metric goes from 0.5 to 1.0, where 0.5 is a random classifier and 1.0 is a perfect classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "UlC1F8-hJr2c"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "BiZPOS_vKtEE"
   },
   "outputs": [],
   "source": [
    "# we are going to get the false positive rates and true positive rates to plot\n",
    "y_pred = model.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "# and the total area under the curve\n",
    "auroc = roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "LD1udTjoK7L5"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "ugrk5logLGJf",
    "outputId": "e4a64adf-0c36-4bc2-ee4f-28060cfbd6be"
   },
   "outputs": [],
   "source": [
    "# plot the ROC\n",
    "fig, axis = plt.subplots()\n",
    "axis.plot(fpr, tpr)\n",
    "axis.set_xlabel('False Positive Rate')\n",
    "axis.set_ylabel('True Positive Rate')\n",
    "\n",
    "axis.plot([0, 1], [0, 1], color='black', linestyle='--')\n",
    "axis.set_xlim([0, 1])\n",
    "axis.set_ylim([0, 1])\n",
    "axis.set_title(f'AUROC: {auroc:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ay_hpG2fXHBr"
   },
   "source": [
    "We can look at the coefficients of our model by examining the `coef_` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9lmVVkA-NgAc",
    "outputId": "78c94cdc-a3e9-470d-96f6-4783da6ff6a7"
   },
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mRL1Mhc9R97B"
   },
   "source": [
    "Since we will need to make this plot often, let's make it into a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "f_Tl5FsvM-C_"
   },
   "outputs": [],
   "source": [
    "def make_auc_plot(y_true: np.ndarray, y_pred: np.ndarray) -> None:\n",
    "    \"\"\"\n",
    "    Make a beautiful plot of the receiver operating characteristic curve\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true: ndarray\n",
    "        An array of the true labels (1s for True, 0s for False)\n",
    "    y_pred: ndarray\n",
    "        An array of the predictions (between 0 and 1)\n",
    "    \n",
    "    \n",
    "    Side Effects\n",
    "    ------------\n",
    "    Produces a matplotlib figure\n",
    "    \"\"\"\n",
    "  \n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "    auroc = roc_auc_score(y_true, y_pred)\n",
    "  \n",
    "    fig, axis = plt.subplots()\n",
    "    axis.plot(fpr, tpr)\n",
    "    axis.set_xlabel('False Positive Rate')\n",
    "    axis.set_ylabel('True Positive Rate')\n",
    "\n",
    "    axis.plot([0, 1], [0, 1], color='black', linestyle='--')\n",
    "    axis.set_xlim([0, 1])\n",
    "    axis.set_ylim([0, 1])\n",
    "    axis.set_title(f'AUROC: {auroc:.2f}')  # using formating codes here https://pyformat.info/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New model types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6YaVMHd7N5jy"
   },
   "source": [
    "## Decision Trees\n",
    "\n",
    "These flexible models can fit complicated functions with interactions between features and ability to handle different data. They tend to not fit that well and to overfit.\n",
    "[Wiki](https://en.wikipedia.org/wiki/Decision_tree) [SKLearn Docs](https://scikit-learn.org/stable/modules/tree.html)\n",
    "\n",
    "An example of a decision tree:\n",
    "\n",
    "![Example Tree](https://scikit-learn.org/stable/_images/sphx_glr_plot_iris_dtc_0021.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "RRW_ftn2LnXU"
   },
   "outputs": [],
   "source": [
    "# again we will import a new model type from sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "GlrLjuRyMvwV"
   },
   "outputs": [],
   "source": [
    "# we initialize the model using the same structure as before\n",
    "tree_model = DecisionTreeClassifier(max_depth=10, min_samples_leaf=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "2f_aCPBrMw3d",
    "outputId": "07512a42-e9bb-4764-c31f-6a2bb1da1a6d"
   },
   "outputs": [],
   "source": [
    "#<TODO: fit the model>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "2DOO0nGaNVqF",
    "outputId": "a69c9adf-1158-493d-89c9-48bf496800b7"
   },
   "outputs": [],
   "source": [
    "y_pred = tree_model.predict_proba(X_train)[:, 1]\n",
    "make_auc_plot(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "oLDfg94FNPsO",
    "outputId": "5056ab28-9d7f-4ddf-d970-fd28e3e3ce7c"
   },
   "outputs": [],
   "source": [
    "#<TODO: do the same, but with the test error>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lM_sRWErQ3Qa"
   },
   "source": [
    "## Add Another Feature\n",
    "\n",
    "Let's add a new feature `MaritalStatus` to our model. We run into a problem in that Marital Status is a feature of different strings. We need to find a way to 'encode' this value into a numeric value.\n",
    "\n",
    "The method we will use here is called 'dummy encoding' or 'one-hot' encoding. We will create a new feature for each string in the old feature and then give that row a 1 for the new feature if it takes that value (e.g. we would create a 'Divorced' feature and then place a 1 in each row that had an `MaritalStatus` value 'Divorced'). Bonus: there are some 'fancier' ways that one could use to encode categorical variables for instance in this [blog post](https://towardsdatascience.com/smarter-ways-to-encode-categorical-data-for-machine-learning-part-1-of-3-6dca2f71b159)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "xEUfQVpqR14t"
   },
   "outputs": [],
   "source": [
    "# We could also do this directly in sklearn:\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\n",
    "marital_status_dummies = pd.get_dummies(df['MaritalStatus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "436oEshZR8xK",
    "outputId": "2539a202-2907-4af4-a809-537d95c7e631"
   },
   "outputs": [],
   "source": [
    "marital_status_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "nmyRs9p7R-XV"
   },
   "outputs": [],
   "source": [
    "#<todo: add 'MaritalStatus' to our list of columns to use>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.get_dummies(df[use_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "p3Th44huSRQa",
    "outputId": "50aa1f37-fe7a-41cc-f032-a7f18c065549"
   },
   "outputs": [],
   "source": [
    "#<TODO: look at the top 5 rows with our new array>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "-ijIYpeYSVAO"
   },
   "outputs": [],
   "source": [
    "# now that we have new columns we need to redo our train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=3523523)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "hr_kKpiiSdJg",
    "outputId": "283e64fa-d643-4a4c-c7b1-cb0ce0859736"
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "yytE2TMTSi-1",
    "outputId": "48e30697-8457-4bb8-b61a-e7933735af5f"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict_proba(X_test)[:, 1]\n",
    "make_auc_plot(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-GnF2JhzT0Q-"
   },
   "source": [
    "Sometimes there are lots of categories. For instance the `NativeCountry` feature has 42 unique values. We want to add this information to our model, but adding 42 features seems like a lot for our simple model. Let's add just an 'indicator' if the person came from the USA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3MMrx2UhTQT6",
    "outputId": "f5453484-438f-4f65-d3d9-985a42891666"
   },
   "outputs": [],
   "source": [
    "#<TODO: confirm the number of unique features is 42>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "PJIhf1peVkd2"
   },
   "outputs": [],
   "source": [
    "# we can add a new column like we would add an entry to a dictionary\n",
    "X['from_USA'] = (df['NativeCountry'] == ' United-States').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "C8t-vbWXVxh6"
   },
   "outputs": [],
   "source": [
    "#<TODO: split again into training and testing>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "qKNGwGRmWBmq",
    "outputId": "9d407d7b-ed00-4293-979a-52fbc9db8081"
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "APviKyfOWDPI",
    "outputId": "8650a708-f169-4343-bf3b-5dbb1dcb86e0"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict_proba(X_test)[:, 1]\n",
    "make_auc_plot(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "fEhami9jW9dY",
    "outputId": "228364b4-2f5d-4266-9177-932487762d62"
   },
   "outputs": [],
   "source": [
    "#<TODO: refit our tree model>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "ljEdO5U9XBoe",
    "outputId": "d95add84-8c15-460e-ce8e-506722cc44b9"
   },
   "outputs": [],
   "source": [
    "#<TODO: and check our test performance>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u7NysoFMZByn"
   },
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "The last step on our journey is to conduct some hyperparameter tuning. We have several parameters that we can set in our Decision Tree, and it is not always obvious what we should set them to. We can use a grid search to find the best model after we change many different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "wTc6NGaLXGX5"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "jtQffaFRXSfd"
   },
   "outputs": [],
   "source": [
    "# initialize our model with the default parameters\n",
    "tree_model = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "1PCphaqmXNPO"
   },
   "outputs": [],
   "source": [
    "# set up a dictionary with lists for the different parameter values\n",
    "param_grid = {'min_samples_leaf': [1, 2, 10, 20, 100], 'min_impurity_decrease': [0.0, 0.1, 0.2]}\n",
    "# initialize our grid searcher\n",
    "grid_searcher = GridSearchCV(tree_model, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "id": "-kDSQ_0zX4SD",
    "outputId": "79e2c9a4-bd00-4356-9fec-e2102b51e1ba"
   },
   "outputs": [],
   "source": [
    "# can call `.fit` just like a single classifier\n",
    "grid_searcher.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "PlG7pjrcX-E8"
   },
   "outputs": [],
   "source": [
    "# get our best model\n",
    "tree_model = grid_searcher.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "aVcT1-1qYFAf",
    "outputId": "c87abbdc-37a4-4c38-80cd-b220808dbb66"
   },
   "outputs": [],
   "source": [
    "tree_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "yU50TI01YrsY",
    "outputId": "a26cda05-1e80-48e9-8b2a-9f754b5fb858"
   },
   "outputs": [],
   "source": [
    "y_pred = tree_model.predict_proba(X_test)[:, 1]\n",
    "make_auc_plot(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rXtmYitsR4dK"
   },
   "source": [
    "# Group time!\n",
    "\n",
    "Some ideas:\n",
    "\n",
    "1. Explore more feature engineering and more features\n",
    "2. Explore other model types:\n",
    "    - ensemble methods: either gradient boosted classifiers or random forests\n",
    "    - GAMs (https://github.com/dswah/pyGAM)\n",
    "    - other classifiers (https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html)\n",
    "3. Explore the data (or model) using visualizations\n",
    "4. Do so clustering analysis of the data\n",
    "5. Mix and match from above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ri4B5X9UR5Ow"
   },
   "source": [
    "## A note on making plots\n",
    "\n",
    "If there is one thing I have learned in Astro grad school it is how to make good plots, things like: labeling axes, having clear style, and choosing the right plot type. These small things will make a big difference when presenting your work to a wide array of audiences.\n",
    "\n",
    "So you want to make some plots...\n",
    "\n",
    "What type of plot do you want to make? If you need inspiration or want to see different options you can check out the sites below.\n",
    "\n",
    "https://www.data-to-viz.com/\n",
    "\n",
    "https://datavizcatalogue.com/index.html\n",
    "\n",
    "http://datavizproject.com/\n",
    "\n",
    "And see some examples of common plots made in different python libraries.\n",
    "\n",
    "http://pythonplot.com/"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DataScienceWorkshop.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
